{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/pyTensor/tf217/tf217/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-16 12:38:43.576961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731760724.902383     849 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731760725.257703     849 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-16 12:38:48.562343: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_733/1469898370.py:1: DtypeWarning: Columns (4,6,9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('preprocessed_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>edited</th>\n",
       "      <th>over_18</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>retrieved_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KYSUAPE</td>\n",
       "      <td>24-06-21 14:55</td>\n",
       "      <td>t2_cwvv6035</td>\n",
       "      <td>olpcjt</td>\n",
       "      <td>11</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hello there everyone ! :) \\n\\nI would like to ...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>884547.0</td>\n",
       "      <td>Black &amp;amp; Brown Kratom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pleasant_Bus1179</td>\n",
       "      <td>29-01-21 21:03</td>\n",
       "      <td>t2_9tr0fjns</td>\n",
       "      <td>olpfwg</td>\n",
       "      <td>20</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I got 5g of weed 1g of coke 1 vodka and 2 stro...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>884547.0</td>\n",
       "      <td>How to crossfade with booze and weed??</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dazzling-Disk-632</td>\n",
       "      <td>28-01-21 15:43</td>\n",
       "      <td>t2_a1gg2f3a</td>\n",
       "      <td>olpgi6</td>\n",
       "      <td>6</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>26-06-22 1:32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Has any body else here smoke so much crack you...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>884547.0</td>\n",
       "      <td>Has any 1 Hylucinated on crack</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spiritually-high</td>\n",
       "      <td>31-03-21 16:56</td>\n",
       "      <td>t2_9lbpxsa0</td>\n",
       "      <td>olpv4a</td>\n",
       "      <td>132</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>26-06-22 1:31</td>\n",
       "      <td>26-06-22 1:31</td>\n",
       "      <td>138.0</td>\n",
       "      <td>I got hella anxiety and I’m hella coked up is ...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>884547.0</td>\n",
       "      <td>can cocaine give anxiety?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frenchbullmese</td>\n",
       "      <td>04-05-21 11:16</td>\n",
       "      <td>t2_bxihe2ze</td>\n",
       "      <td>olqjjx</td>\n",
       "      <td>14</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>26-06-22 1:31</td>\n",
       "      <td>26-06-22 1:31</td>\n",
       "      <td>18.0</td>\n",
       "      <td>I haven’t been so rude as to say these things ...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>884546.0</td>\n",
       "      <td>Help me lol. My mom has been talking to my cou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author author_created_utc author_fullname      id num_comments  \\\n",
       "0            KYSUAPE     24-06-21 14:55     t2_cwvv6035  olpcjt           11   \n",
       "1   Pleasant_Bus1179     29-01-21 21:03     t2_9tr0fjns  olpfwg           20   \n",
       "2  Dazzling-Disk-632     28-01-21 15:43     t2_a1gg2f3a  olpgi6            6   \n",
       "3   spiritually-high     31-03-21 16:56     t2_9lbpxsa0  olpv4a          132   \n",
       "4     Frenchbullmese     04-05-21 11:16     t2_bxihe2ze  olqjjx           14   \n",
       "\n",
       "  edited over_18   retrieved_on  retrieved_utc  score  \\\n",
       "0  FALSE    TRUE  26-06-22 1:32  26-06-22 1:32    2.0   \n",
       "1  FALSE    TRUE  26-06-22 1:32  26-06-22 1:32    1.0   \n",
       "2  FALSE    TRUE  26-06-22 1:32  26-06-22 1:32    0.0   \n",
       "3  FALSE    TRUE  26-06-22 1:31  26-06-22 1:31  138.0   \n",
       "4  FALSE    TRUE  26-06-22 1:31  26-06-22 1:31   18.0   \n",
       "\n",
       "                                            selftext subreddit subreddit_id  \\\n",
       "0  Hello there everyone ! :) \\n\\nI would like to ...     Drugs     t5_2qh7l   \n",
       "1  I got 5g of weed 1g of coke 1 vodka and 2 stro...     Drugs     t5_2qh7l   \n",
       "2  Has any body else here smoke so much crack you...     Drugs     t5_2qh7l   \n",
       "3  I got hella anxiety and I’m hella coked up is ...     Drugs     t5_2qh7l   \n",
       "4  I haven’t been so rude as to say these things ...     Drugs     t5_2qh7l   \n",
       "\n",
       "  subreddit_subscribers                                              title  \\\n",
       "0              884547.0                           Black &amp; Brown Kratom   \n",
       "1              884547.0             How to crossfade with booze and weed??   \n",
       "2              884547.0                     Has any 1 Hylucinated on crack   \n",
       "3              884547.0                          can cocaine give anxiety?   \n",
       "4              884546.0  Help me lol. My mom has been talking to my cou...   \n",
       "\n",
       "   total_awards_received  upvote_ratio  word_count  \n",
       "0                    0.0          1.00        33.0  \n",
       "1                    0.0          0.56        38.0  \n",
       "2                    0.0          0.38        32.0  \n",
       "3                    0.0          0.94        21.0  \n",
       "4                    0.0          0.96       532.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sentiment column\n",
    "df['sentiment'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_created_utc', 'author_fullname', 'id', 'num_comments',\n",
       "       'edited', 'over_18', 'retrieved_on', 'retrieved_utc', 'score',\n",
       "       'selftext', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'title', 'total_awards_received', 'upvote_ratio', 'word_count',\n",
       "       'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "I0000 00:00:1731604046.283603     733 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = pipeline(\"sentiment-analysis\" , framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "/tmp/ipykernel_733/25970713.py:9: DtypeWarning: Columns (4,6,9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/mnt/d/pyTensor/tf217/Reddit/preprocessed_data.csv')\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Completed\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the sentiment analysis pipeline with TensorFlow backend\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", framework=\"tf\")\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/mnt/d/pyTensor/tf217/Reddit/preprocessed_data.csv')\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16  # You can adjust this based on your GPU memory\n",
    "\n",
    "# Function to analyze sentiment in batches\n",
    "def analyze_sentiment_batch(texts):\n",
    "    results = sentiment_analysis(texts)\n",
    "    sentiments = []\n",
    "    for result in results:\n",
    "        score = result['score']\n",
    "        label = result['label']\n",
    "        \n",
    "        if label == 'POSITIVE' and score >= 0.6:\n",
    "            sentiments.append('positive')\n",
    "        elif label == 'NEGATIVE' and score >= 0.6:\n",
    "            sentiments.append('negative')\n",
    "        else:\n",
    "            sentiments.append('neutral')\n",
    "    \n",
    "    return sentiments\n",
    "\n",
    "# Process the selftext column in batches\n",
    "texts = df['selftext'].fillna(\"\").tolist()  # Replace non-string values with empty strings\n",
    "sentiments = []\n",
    "\n",
    "# Process data in batches and collect sentiment results\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    sentiments.extend(analyze_sentiment_batch(batch))\n",
    "\n",
    "# Add results to DataFrame\n",
    "df['sentiment'] = sentiments\n",
    "\n",
    "# Save the DataFrame with the new sentiment column\n",
    "df.to_csv('/mnt/d/pyTensor/tf217/Reddit/sentiment_data.csv', index=False)\n",
    "print(\"Sentiment Analysis Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    74139\n",
       "positive    18414\n",
       "neutral      1529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849/1418777235.py:1: DtypeWarning: Columns (4,6,9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('sentiment_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('sentiment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                    78\n",
       "author_created_utc       102\n",
       "author_fullname          119\n",
       "id                       133\n",
       "num_comments             139\n",
       "edited                   143\n",
       "over_18                  148\n",
       "retrieved_on             149\n",
       "retrieved_utc            155\n",
       "score                    158\n",
       "selftext                 158\n",
       "subreddit                163\n",
       "subreddit_id             165\n",
       "subreddit_subscribers    167\n",
       "title                    168\n",
       "total_awards_received    170\n",
       "upvote_ratio             170\n",
       "word_count               171\n",
       "sentiment                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing NAN values from the datset\n",
    "df2.dropna(subset=['author', 'author_created_utc', 'author_fullname', 'id', 'num_comments', 'edited', 'over_18', 'retrieved_on', 'retrieved_utc', 'score', 'selftext', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'title', 'total_awards_received', 'upvote_ratio', 'word_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                   0\n",
       "author_created_utc       0\n",
       "author_fullname          0\n",
       "id                       0\n",
       "num_comments             0\n",
       "edited                   0\n",
       "over_18                  0\n",
       "retrieved_on             0\n",
       "retrieved_utc            0\n",
       "score                    0\n",
       "selftext                 0\n",
       "subreddit                0\n",
       "subreddit_id             0\n",
       "subreddit_subscribers    0\n",
       "title                    0\n",
       "total_awards_received    0\n",
       "upvote_ratio             0\n",
       "word_count               0\n",
       "sentiment                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93911"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24-06-21 14:55\n",
       "1    29-01-21 21:03\n",
       "2    28-01-21 15:43\n",
       "3    31-03-21 16:56\n",
       "4    04-05-21 11:16\n",
       "5     20-05-21 1:58\n",
       "6    01-03-20 22:11\n",
       "7    28-11-18 18:01\n",
       "8    09-02-15 19:38\n",
       "9    03-11-20 22:27\n",
       "Name: author_created_utc, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['author_created_utc'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['author_created_utc'] = pd.to_datetime(df2['author_created_utc'], format='%d-%m-%y %H:%M', errors='coerce')\n",
    "df2['retrieved_on'] = pd.to_datetime(df2['retrieved_on'], format='%d-%m-%y %H:%M', errors='coerce')\n",
    "df2['retrieved_utc'] = pd.to_datetime(df2['retrieved_utc'], format='%d-%m-%y %H:%M', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '/mnt/d/pyTensor/tf217/Reddit/updated_sentiment_data.csv'\n",
    "df2.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
